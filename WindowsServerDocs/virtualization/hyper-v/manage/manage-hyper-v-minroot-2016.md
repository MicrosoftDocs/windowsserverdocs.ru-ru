---
title: минрут
description: Настройка элементов управления ресурсами ЦП узла
ms.author: benarm
author: BenjaminArmstrong
ms.date: 12/15/2017
ms.topic: article
ms.openlocfilehash: 4a222151a9236fb19ef98eda2526524f2d113094
ms.sourcegitcommit: dd1fbb5d7e71ba8cd1b5bfaf38e3123bca115572
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/17/2020
ms.locfileid: "90746589"
---
# <a name="hyper-v-host-cpu-resource-management"></a>Управление ресурсами ЦП узла Hyper-V

Элементы управления ресурсами ЦП узла Hyper-V, появившиеся в Windows Server 2016 или более поздней версии, позволяют администраторам Hyper-V лучше управлять и распределять ресурсы ЦП хост-сервера между "корневой", "разделом управления" и гостевыми виртуальными машинами.
С помощью этих элементов управления администраторы могут выделить подмножество процессоров хост-системы в корневом разделе.
Это позволяет отделить работу, выполненную на узле Hyper-V, от рабочих нагрузок, работающих на гостевых виртуальных машинах, запустив их на отдельных подмножествах системных процессоров.

Дополнительные сведения об оборудовании для узлов Hyper-V см. в статье [требования к системе для Hyper-v в Windows 10](/virtualization/hyper-v-on-windows/reference/hyper-v-requirements).

## <a name="background"></a>Фон

Перед настройкой элементов управления для ресурсов ЦП узла Hyper-V полезно ознакомиться с основами архитектуры Hyper-V.
Общую сводку можно найти в разделе об [архитектуре Hyper-V](../../../administration/performance-tuning/role/hyper-v-server/architecture.md) .
Ниже приведены важные понятия, связанные с этой статьей.

* Hyper-V создает и управляет секциями виртуальных машин, в рамках которых ресурсы вычислений распределяются и совместно используются, под контролем гипервизора.  Секции обеспечивают строгие границы изоляции между всеми гостевыми виртуальными машинами, а также между гостевыми и корневыми машинами.

* Корневой раздел сам является разделом виртуальной машины, хотя у него есть уникальные свойства и более широкие привилегии, чем Гостевые виртуальные машины.  Корневой раздел предоставляет службы управления, управляющие всеми гостевыми виртуальными машинами, обеспечивает поддержку виртуальных устройств для гостей и управляет всеми операциями ввода-вывода для гостевых виртуальных машин.  Корпорация Майкрософт настоятельно рекомендует не выполнять какие-либо рабочие нагрузки приложений в разделе узла.

* Каждый виртуальный процессор (вице-президент) корневого раздела сопоставляется с 1:1 базовым логическим процессором (LP).  Вице-президент узла всегда будет выполняться на том же самом базовом LP — миграция ВПС корневого раздела отсутствует.

* По умолчанию LPs, на котором размещен ВПС, может также запускать гостевой ВПС.

* Низкоуровневая виртуальная машина может быть запланирована для запуска на любом доступном логическом процессоре.  В то время как планировщик низкоуровневой оболочки следит за локализацией временного кэша, топологией NUMA и многими другими факторами при планировании гостевого вице-президента, в конечном счете, его можно запланировать на любом сервере LP.

## <a name="the-minimum-root-or-minroot-configuration"></a>Минимальная корневая папка или Конфигурация "Минрут"

В ранних версиях Hyper-V был установлен максимальный архитектурный лимит в 64 ВПС на секцию.  Это применяется как к корневым, так и к гостевым секциям.  Так как системы с более чем 64 логическими процессорами появлялись на серверах высокого уровня, Hyper-V также расширил ограничения масштабирования узлов для поддержки этих крупных систем, в то же время достигая узла до 320 LPs.  Тем не менее, при достижении предельного количества килограммов 64 на секцию в это время представлены несколько проблем и появились сложности, которые делают поддержку более 64 ВПС на секцию.  Чтобы решить эту эту технологию, Hyper-V ограничивает количество ВПС, присвоенное корневому разделу, равным 64, даже если на базовом компьютере доступно гораздо больше логических процессоров.  Гипервизор будет по прежнему использовать все доступные LPs для запуска гостевых ВПС, но искусственно ограниченный корневой раздел 64.  Эта конфигурация называлась "минимальной корневой конфигурацией" или "минрут".  Тестирование производительности подтвердило, что даже в крупных системах с более чем 64 LPs, корню не требуется более 64 корневого ВПС, чтобы обеспечить достаточную поддержку для большого количества гостевых виртуальных машин и гостевых ВПС. на самом деле, гораздо меньше 64 корневых ВПС, в зависимости от количества и размера гостевых виртуальных машин. , выполняемые рабочие нагрузки и т. д.

Эта концепция "минрут" будет продолжать использоваться сегодня.  На самом деле, даже так как Windows Server 2016 Hyper-V увеличила максимальное ограничение на архитектурную поддержку для узла LPs до 512 LPs, корневой раздел по-прежнему будет ограничен максимум 320 LPs.

## <a name="using-minroot-to-constrain-and-isolate-host-compute-resources"></a>Использование Минрут для ограничения и изоляции ресурсов вычислений узла
Благодаря высокому пороговому значению по умолчанию 320 LPs в Windows Server 2016 Hyper-V, конфигурация минрут будет использоваться только в самых больших серверных системах.  Однако эту возможность можно настроить на более низкое пороговое значение для администратора узла Hyper-V и, таким же, использовать для значительного ограничения объема ресурсов ЦП узла, доступных корневому разделу.  Необходимо тщательно выбрать определенное количество используемых корневых LPs, чтобы обеспечить максимальную нагрузку на виртуальные машины и рабочие нагрузки, выделенные узлу.  Однако разумные значения для числа узлов LPs можно определить с помощью тщательной оценки и мониторинга рабочих нагрузок, а также проверки в нерабочих средах перед широким развертыванием.

## <a name="enabling-and-configuring-minroot"></a>Включение и настройка Минрут

Конфигурация минрут контролируется с помощью записей BCD гипервизора. Чтобы включить минрут, в командной строке с правами администратора выполните следующую команду:

```
     bcdedit /set hypervisorrootproc n
```
Где n — число корневых ВПС.

Система должна быть перезагружена, а новое число корневых процессоров будет сохранено в течение времени существования загрузки операционной системы.  Конфигурацию минрут невозможно динамически изменить во время выполнения.

При наличии нескольких узлов NUMA каждый узел будет получать `n/NumaNodeCount` процессоры.

Обратите внимание, что с несколькими узлами NUMA необходимо убедиться в том, что топология виртуальной машины имеет достаточно свободного LPs (т. е. LPs без корневого ВПС) на каждом узле NUMA для запуска узла NUMA соответствующей виртуальной машины.

## <a name="verifying-the-minroot-configuration"></a>Проверка конфигурации Минрут

Конфигурацию минрут узла можно проверить с помощью диспетчера задач, как показано ниже.

![Конфигурация минрут узла, отображаемая в диспетчере задач](./media/minroot-taskman.png)

Когда Минрут активен, диспетчер задач отображает количество логических процессоров, выделенных в данный момент узлу, а также общее число логических процессоров в системе.