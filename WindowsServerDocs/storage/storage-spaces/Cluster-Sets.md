---
title: Наборы кластеров
ms.prod: windows-server
manager: eldenc
ms.technology: storage-spaces
ms.topic: article
author: johnmarlin-msft
ms.author: johnmar
ms.date: 01/30/2019
description: В этой статье описывается сценарий наборов кластеров.
ms.localizationpriority: medium
ms.openlocfilehash: 64aeda27d5554e3f348a77b0ae785ddcf05dee00
ms.sourcegitcommit: bf887504703337f8ad685d778124f65fe8c3dc13
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/16/2020
ms.locfileid: "83436619"
---
# <a name="cluster-sets"></a>Наборы кластеров

> Применяется к: Windows Server 2019

Наборы кластеров — это новая облачная технология масштабирования в выпуске Windows Server 2019, увеличивающая число узлов кластера в одном программно определенном облаке центра обработки данных (SDDC) в соответствии с порядком. Набор кластеров — это слабо связанное Группирование нескольких отказоустойчивых кластеров: вычислений, хранения или Hyper-схождения. Технология наборов кластеров обеспечивает возможность объединения виртуальных машин между кластерами членов в наборе кластеров и единым пространством имен хранилища в пределах набора для поддержки жидкости виртуальных машин.

При сохранении существующих возможностей управления отказоустойчивыми кластерами в кластерах членов экземпляр набора кластеров дополнительно предоставляет Ключевые варианты использования для управления жизненным циклом в статистической обработке. В этом руководствах по ознакомлению с Windows Server 2019 приведены необходимые фундаментальные сведения, а также пошаговые инструкции по оценке технологии наборов кластеров с помощью PowerShell.

## <a name="technology-introduction"></a>Введение в технологию

Технология наборов кластеров разрабатывается для удовлетворения конкретных клиентов, которые задаются в масштабируемом программном обеспечении. Предложение о значении кластера может быть представлено следующим образом:

- Значительно увеличить поддерживаемое облачное масштабирование SDDC для запуска высокодоступных виртуальных машин путем объединения нескольких небольших кластеров в одну крупную структуру даже при хранении границы сбоя программного обеспечения в одном кластере.
- Управление всем жизненным циклом отказоустойчивого кластера, включая подключение и удаление кластеров без влияния на доступность виртуальных машин клиента, с помощью бесплатной миграции виртуальных машин в этой крупной структуре
- Простое изменение соотношения вычисления и хранилища в вашей технологии Hyper-by
- Преимущества [доменов сбоя и групп доступности Azure](htttps://docs.microsoft.com/azure/virtual-machines/windows/manage-availability) в разных кластерах при первоначальном размещении виртуальных машин и последующей миграции виртуальных машин
- Смешивание и сопоставление различных поколений аппаратного обеспечения в одной структуре набора кластеров, даже при хранении отдельных доменов сбоя в однородном режиме для максимальной эффективности. Обратите внимание, что рекомендация того же оборудования по-прежнему имеется в каждом отдельном кластере, а также в целом наборе кластеров.

Из представления высокого уровня это может выглядеть как набор кластеров.

![Кластер устанавливает представление решения](media/Cluster-sets-Overview/Cluster-sets-solution-View.png)

Ниже приведена краткая сводка по каждому элементу на изображении выше.

**Кластер управления**

Кластер управления в наборе кластеров — это отказоустойчивый кластер, на котором размещена плоскость высокой доступности для всего набора кластеров, а также ссылка на унифицированное пространство имен хранилища (пространство имен набора кластеров) масштабируемый файловый сервер (SOFS). Кластер управления логически отделяется от кластеров-членов, на которых выполняются рабочие нагрузки виртуальных машин. Это делает плоскость управления кластера отказоустойчивой для любых локализованных сбоев в масштабе всего кластера, например потери возможностей кластера членов.

**Кластер членов**

Кластером членов в наборе кластеров обычно являются традиционные рабочие нагрузки, работающие под управлением виртуальных машин с технологией Hyper-Clustering и Локальные дисковые пространства. Кластеры с несколькими участниками участвуют в развертывании одного набора кластеров, образуя более крупную облачную структуру SDDC. Кластеры-члены отличаются от кластера управления в двух ключевых аспектах: кластеры членов участвуют в конструкциях домена сбоя и группы доступности, а также размеры кластеров-членов для размещения виртуальных машин и Локальные дисковые пространства рабочих нагрузок. Виртуальные машины с наборами кластеров, перемещаемые между границами кластера в наборе кластеров, не должны размещаться в кластере управления по этой причине.

**Ссылка на пространство имен набора кластеров SOFS**

Ссылка на пространство имен набора кластеров (пространство имен набора кластеров) SOFS является масштабируемый файловый сервер, где каждая общая папка SMB в пространстве имен набора SOFS является ссылочной общей папкой — типа "Симплереферрал", появившейся в Windows Server 2019. Эта ссылка позволяет клиентам SMB получать доступ к целевой общей папке SMB, размещенной на SOFS кластере участников. Пространство имен набора кластеров SOFS является облегченным механизмом ссылок и, таким образом, не участвует в пути ввода-вывода. Ссылки SMB кэшируются на каждом из клиентских узлов, а кластер устанавливает динамическое обновление автоматически при необходимости.

**Мастер набора кластеров**

В наборе кластеров связь между кластерами членов слабо связана и координируется новым ресурсом кластера под названием "главный набор кластера" (CS-Master). Как и любой другой ресурс кластера, CS-Master является высокодоступным и устойчивым к сбоям кластера отдельных участников и (или) сбоям узла кластера управления. С помощью нового поставщика WMI набора кластеров CS-Master предоставляет конечную точку управления для всех взаимодействий управления кластерами.

**Рабочий процесс набора кластеров**

В развертывании набора кластеров CS-Master взаимодействует с новым ресурсом кластера в кластерах-членах, называемых "Рабочий процесс кластера" (CS-Worker). CS-Worker действует как единственная связь в кластере для координации взаимодействия локального кластера согласно запросу CS-Master. Примерами таких взаимодействий могут служить размещение виртуальных машин и Инвентаризация ресурсов в локальной кластеризации. Для каждого из кластеров-членов в наборе кластеров существует только один экземпляр роли CS-Worker.

**Домен сбоя**

Домен сбоя — это группирование артефактов программного и аппаратного обеспечения, которые администратор может выполнить совместно со сбоем при возникновении сбоя. Хотя Администратор может назначить один или несколько кластеров вместе с доменом сбоя, каждый узел может участвовать в домене сбоя в группе доступности. Набор кластеров, создаваемых в результате проектирования, оставляет за собой решение определить границу домена сбоя для администратора, который хорошо подходит для топологии центров обработки данных, например PDU, Networking (общий ресурс кластеров-членов).

**Группа доступности**

Группа доступности помогает администратору настроить требуемую избыточность кластеризованных рабочих нагрузок в доменах сбоя, организуя их в группу доступности и развертывая рабочие нагрузки в этой группе доступности. Предположим, что при развертывании двухуровневых приложения мы рекомендуем настроить по крайней мере две виртуальные машины в группе доступности для каждого уровня, что гарантирует, что при отключении одного домена сбоя в группе доступности приложение будет иметь по крайней мере одну виртуальную машину на каждом уровне, размещенном в другом домене сбоя той же группы доступности.

## <a name="why-use-cluster-sets"></a>Зачем использовать наборы кластеров

Кластерные наборы предоставляют преимущество масштабирования без ущерба для устойчивости.

Кластерные наборы позволяют кластеризацию нескольких кластеров вместе для создания большой структуры, в то время как каждый кластер остается независимым для обеспечения устойчивости. Например, имеется несколько кластеров ХЦИ с 4 узлами, работающих под управлением виртуальных машин. Каждый кластер обеспечивает устойчивость, необходимую для самого себя. Если в хранилище или памяти начинается заполнение, то на следующем шаге происходит масштабирование. С увеличением масштаба существует несколько параметров и рекомендаций.

1. Добавьте дополнительное хранилище в текущий кластер. С Локальные дисковые пространства это может быть непросто, так как одни и те же диски модели и встроенного по могут быть недоступны. Также необходимо учитывать время перестроения.
2. Добавьте дополнительную память. Что делать, если вы израсходоване память, которую могут выполнять компьютеры?  Что если все доступные слоты памяти заполнены?
3. Добавьте дополнительные расчетные узлы с дисками в текущий кластер. Мы вернемся к варианту 1, который необходимо учитывать.
4. Приобретение всего нового кластера

Именно здесь наборы кластеров предоставляют преимущество масштабирования. При добавлении кластеров в набор кластеров можно воспользоваться преимуществами хранилища или памяти, которые могут быть доступны в другом кластере без дополнительных покупок. С точки зрения устойчивости Добавление дополнительных узлов в Локальные дисковые пространства не будет предоставлять дополнительные голоса для кворума. Как упоминалось [здесь](drive-symmetry-considerations.md), кластер Локальные дисковые пространства может сохранить потери 2 узлов, прежде чем переходить к следующему. Если кластер ХЦИ с 4 узлами, то 3 узла перейдут весь кластер. Если вы используете кластер с 8 узлами, то 3 узла перейдут в кластер все три узла. Если в наборе кластеров имеется два ХЦИ кластера из 4 узлов, 2 узла в одном ХЦИ, и 1 узел в другом ХЦИ, оба кластера остаются. Лучше ли создать один кластер с большим размером 16 узлов Локальные дисковые пространства или разбить его на четыре кластера из 4 узлов и использовать наборы кластеров?  Наличие четырех кластеров из 4 узлов с наборами кластеров обеспечивает одинаковую масштабируемость, но более надежную устойчивость в том, что несколько процессорных узлов могут переключаться (неожиданно или для обслуживания) и оставаться в производстве.

## <a name="considerations-for-deploying-cluster-sets"></a>Рекомендации по развертыванию наборов кластеров

При рассмотрении того, какие наборы кластеров необходимо использовать, учитывайте следующие вопросы.

- Требуется ли выход за пределы текущих вычислений ХЦИ и масштабирования хранилища?
- Все ли операции вычислений и хранения не одинаковы?
- Вы выполняете динамическую миграцию виртуальных машин между кластерами?
- Хотите ли вы, например, группы доступности компьютеров Azure и домены сбоя в нескольких кластерах?
- Требуется ли время для просмотра всех кластеров, чтобы определить, где следует разместить новые виртуальные машины?

Если вы ответили да, то набор кластеров — это то, что вам нужно.

Существует несколько других элементов, которые следует учитывать, когда в центре управления мобильными данными может измениться общая стратегия центра обработки данных. Хорошим примером является SQL Server. Требуется ли выполнение лицензирования SQL на дополнительных узлах при перемещении SQL Server виртуальных машин между кластерами?

## <a name="scale-out-file-server-and-cluster-sets"></a>Масштабируемый файловый сервер и наборы кластеров

В Windows Server 2019 существует новая роль масштабируемого файлового сервера с именем Infrastructure масштабируемый файловый сервер (SOFS).

Следующие рекомендации относятся к роли SOFS инфраструктуры.

1. В отказоустойчивом кластере может быть только одна роль кластера SOFS инфраструктуры. Роль SOFS инфраструктуры создается путем указания параметра **-Infrastructure**в командлете **Add-клустерскалеаутфилесерверроле** . Пример:

    ```PowerShell
    Add-ClusterScaleoutFileServerRole -Name "my_infra_sofs_name" -Infrastructure
    ```

2. Каждый том CSV, созданный при отработке отказа, автоматически активирует создание общего ресурса SMB с автоматически созданным именем на основе имени тома CSV. Администратор не может напрямую создавать или изменять общие ресурсы SMB в роли SOFS, кроме операций создания и изменения томов CSV.

3. В конфигурациях с согласованием в технологии Hyper-SOFS инфраструктура позволяет клиенту SMB (узлу Hyper-V) взаимодействовать с гарантированной непрерывной доступностью (CA) с сервером SMB инфраструктуры SOFS. Этот ЦС с согласованием по протоколу SMB использует виртуальные машины, обращающиеся к своим файлам виртуального диска (VHDx), в которые пересылается удостоверение виртуальной машины-владельца между клиентом и сервером. Эта переадресация удостоверений разрешает VHDx-файлы с помощью ACL так же, как и в стандартных конфигурациях кластера с поддержкой Hyper-in.

После создания кластера пространство имен набора кластеров основывается на инфраструктуре, SOFS на каждом из кластеров членов, а также в SOFS инфраструктуры в кластере управления.

В момент добавления кластера членов в набор кластеров администратор указывает имя инфраструктуры, SOFS в этом кластере, если он уже существует. Если инфраструктура SOFS не существует, эта операция создает новую роль SOFS инфраструктуры в новом кластере-члене. Если роль SOFS инфраструктуры уже существует в кластере участников, операция добавления неявно переименовывает ее в указанное имя по мере необходимости. Все существующие одноэлементные SMB-серверы или роли SOFS, не относящиеся к инфраструктуре, не используются кластером членов.

На момент создания кластера администратор может использовать уже существующий объект компьютера AD в качестве корня пространства имен в кластере управления. Операции создания набора кластеров создают роль кластера SOFS инфраструктуры в кластере управления или Переименовывает существующую роль SOFS инфраструктуры, как описано выше для кластеров членов. Инфраструктура SOFS в кластере управления используется в качестве ссылки на пространство имен набора кластеров (пространство имен кластера) SOFS. Это просто означает, что каждый общий ресурс SMB в кластере с пространством имен SOFS является ссылочной общей папкой — типа "Симплереферрал" — впервые появился в Windows Server 2019. Эта ссылка позволяет клиентам SMB получать доступ к целевой общей папке SMB, размещенной в кластере участников SOFS. Пространство имен набора кластеров SOFS является облегченным механизмом ссылок и, таким образом, не участвует в пути ввода-вывода. Ссылки SMB кэшируются на каждом из узлов клиента, и кластер устанавливает динамическое обновление для них автоматически при необходимости.

## <a name="creating-a-cluster-set"></a>Создание набора кластеров

### <a name="prerequisites"></a>Предварительные условия

При создании набора кластеров рекомендуется выполнять следующие предварительные требования.

1. Настройка клиента управления под управлением Windows Server 2019.
2. Установите средства отказоустойчивого кластера на этом сервере управления.
3. Создание элементов кластера (по крайней мере два кластера с общими томами кластера по меньшей мере на каждом кластере)
4. Создайте кластер управления (физический или гостевой), на котором находятся кластеры членов. Такой подход гарантирует, что уровень управления кластера будет доступен, несмотря на возможные сбои в работе кластера.

### <a name="steps"></a>Шаги

1. Создайте новый набор кластеров из трех кластеров, как определено в предварительных требованиях. На приведенной ниже диаграмме приведен пример создаваемых кластеров. В этом примере в качестве имени кластера будет использоваться **ксмастер**.

   | Имя кластера, | Имя SOFS инфраструктуры, которое будет использоваться позже |
   |--------------|-------------------------------------------|
   | SET-CLUSTER  | SOFS-CLUSTERING                           |
   | CLUSTER1     | SOFS — CLUSTER1                             |
   | CLUSTER2     | SOFS — CLUSTER2                             |

2. После создания всех кластеров выполните следующую команду, чтобы создать мастер набора кластеров.

    ```PowerShell
    New-ClusterSet -Name CSMASTER -NamespaceRoot SOFS-CLUSTERSET -CimSession SET-CLUSTER
    ```

3. Используйте приведенный ниже набор команд, чтобы добавить сервер кластера в набор кластеров.

    ```PowerShell
    Add-ClusterSetMember -ClusterName CLUSTER1 -CimSession CSMASTER -InfraSOFSName SOFS-CLUSTER1
    Add-ClusterSetMember -ClusterName CLUSTER2 -CimSession CSMASTER -InfraSOFSName SOFS-CLUSTER2
    ```

   > [!NOTE]
   > При использовании схемы статических IP-адресов необходимо включить параметр *-статикаддресс x. x. x. x* в команде **New-Clustering** .

4. После создания кластера, установленного для членов кластера, можно вывести список узлов и его свойства. Чтобы перечислить все кластеры элементов в наборе кластеров, выполните следующие действия.

    ```PowerShell
    Get-ClusterSetMember -CimSession CSMASTER
    ```

5. Для перечисления всех кластеров элементов в наборе кластеров, включая узлы кластера управления, выполните следующие действия.

    ```PowerShell
    Get-ClusterSet -CimSession CSMASTER | Get-Cluster | Get-ClusterNode
    ```

6. Чтобы получить список всех узлов из кластеров участников, выполните следующие действия.

    ```PowerShell
    Get-ClusterSetNode -CimSession CSMASTER
    ```

7. Чтобы получить список всех групп ресурсов в наборе кластеров, выполните следующие действия.

    ```PowerShell
    Get-ClusterSet -CimSession CSMASTER | Get-Cluster | Get-ClusterGroup
    ```

8. Чтобы убедиться, что процесс создания набора кластеров создал одну общую папку SMB (определенную как Volume1, или любую папку CSV с меткой, ScopeName — это имя серверного файла инфраструктуры и путь как и то, и другое) в SOFS инфраструктуры для каждого тома кластера каждого из этих членов.

    ```PowerShell
    Get-SmbShare -CimSession CSMASTER
    ```

9. Для проверки можно собирать журналы отладки для набора кластеров. Кластерный набор и журналы отладки кластера можно собирать для всех членов и кластера управления:

    ```PowerShell
    Get-ClusterSetLog -ClusterSetCimSession CSMASTER -IncludeClusterLog -IncludeManagementClusterLog -DestinationFolderPath <path>
    ```

10. Настройте [ограниченное делегирование](https://techcommunity.microsoft.com/t5/virtualization/live-migration-via-constrained-delegation-with-kerberos-in/ba-p/382334) Kerberos между всеми членами набора кластеров.

11. Настройте для типа проверки подлинности динамической миграции виртуальной машины между кластерами протокол Kerberos на каждом узле в наборе кластеров.

    ```PowerShell
    foreach($h in $hosts){ Set-VMHost -VirtualMachineMigrationAuthenticationType Kerberos -ComputerName $h }
    ```

12. Добавьте кластер управления в локальную группу администраторов на каждом узле в наборе кластеров.

    ```PowerShell
    foreach($h in $hosts){ Invoke-Command -ComputerName $h -ScriptBlock {Net localgroup administrators /add <management_cluster_name>$} }
    ```

## <a name="creating-new-virtual-machines-and-adding-to-cluster-sets"></a>Создание новых виртуальных машин и добавление их в наборы кластеров

Следующим шагом после создания набора кластеров является создание новых виртуальных машин. Обычно, когда нужно создать виртуальные машины и добавить их в кластер, необходимо выполнить некоторые проверки на кластерах, чтобы узнать, какие из них лучше использовать. Эти проверки могут включать:

- Сколько памяти доступно на узлах кластера?
- Сколько места на диске доступно на узлах кластера?
- Требуются ли для виртуальной машины определенные требования к хранилищу (т. е. я хочу, чтобы мои SQL Server виртуальные машины были подключены к кластеру с более быстрыми дисками, а виртуальная машина инфраструктуры не столь важна и может работать на более медленных дисках).

После получения ответов на эти вопросы вы создадите виртуальную машину в кластере. Одним из преимуществ наборов кластеров является то, что наборы кластеров выполняют эти проверки и размещают виртуальную машину на наиболее оптимальном узле.

Приведенные ниже команды будут указывать оптимальный кластер и развернуть в нем виртуальную машину. В приведенном ниже примере создается новая виртуальная машина, указывающая, что для виртуальной машины доступно по крайней мере 4 гигабайта памяти и потребуется использовать 1 виртуальный процессор.

- Убедитесь, что для виртуальной машины доступен 4 ГБ.
- Задайте виртуальный процессор, используемый в 1
- Убедитесь, что для виртуальной машины доступно по меньшей мере 10% ресурсов ЦП.

```PowerShell
# Identify the optimal node to create a new virtual machine
$memoryinMB=4096
$vpcount = 1
$targetnode = Get-ClusterSetOptimalNodeForVM -CimSession CSMASTER -VMMemory $memoryinMB -VMVirtualCoreCount $vpcount -VMCpuReservation 10
$secure_string_pwd = convertto-securestring "<password>" -asplaintext -force
$cred = new-object -typename System.Management.Automation.PSCredential ("<domain\account>",$secure_string_pwd)

# Deploy the virtual machine on the optimal node
Invoke-Command -ComputerName $targetnode.name -scriptblock { param([String]$storagepath); New-VM CSVM1 -MemoryStartupBytes 3072MB -path $storagepath -NewVHDPath CSVM.vhdx -NewVHDSizeBytes 4194304 } -ArgumentList @("\\SOFS-CLUSTER1\VOLUME1") -Credential $cred | Out-Null

Start-VM CSVM1 -ComputerName $targetnode.name | Out-Null
Get-VM CSVM1 -ComputerName $targetnode.name | fl State, ComputerName
```

По завершении вы получите сведения о виртуальной машине и месте ее размещения. В приведенном выше примере будет показано следующее:

```
State         : Running
ComputerName  : 1-S2D2
```

Если вам не хватает памяти, объема ЦП или дискового пространства для добавления виртуальной машины, вы получите следующую ошибку:

```
Get-ClusterSetOptimalNodeForVM : A cluster node is not available for this operation.
```

После создания виртуальной машины она будет отображаться в диспетчере Hyper-V на указанном узле. Чтобы добавить его в качестве виртуальной машины набора кластеров и добавить его в кластер, выполните следующую команду:

```PowerShell
Register-ClusterSetVM -CimSession CSMASTER -MemberName $targetnode.Member -VMName CSVM1
```

После завершения будет выведен результат:

```
Id  VMName  State  MemberName  PSComputerName
--  ------  -----  ----------  --------------
 1  CSVM1     On   CLUSTER1    CSMASTER
```

Если вы добавили кластер с существующими виртуальными машинами, виртуальные машины также потребуется зарегистрировать в наборах кластеров. Чтобы зарегистрировать все эти виртуальные машины одновременно, используйте следующие команды:

```PowerShell
Get-ClusterSetMember -Name CLUSTER3 -CimSession CSMASTER | Register-ClusterSetVM -RegisterAll -CimSession CSMASTER
```

Однако процесс еще не завершен, так как путь к виртуальной машине необходимо добавить в пространство имен набора кластеров.

Например, добавлен существующий кластер, который содержит предварительно настроенные виртуальные машины, расположенные на локальном общий том кластера (CSV). Путь для VHDX будет выглядеть примерно так: «C:\ClusterStorage\Volume1\MYVM\Virtual Hard Дискс\мивм.вхдкс». Необходимо выполнить миграцию хранилища, так как пути CSV являются локальными для одного одноэлементного кластера и, следовательно, недоступны для виртуальной машины после их динамического переноса в кластерах участников.

В этом примере CLUSTER3 был добавлен в набор кластеров с помощью Add-Клустерсетмембер с инфраструктурой масштабируемый файловый сервер как SOFS-CLUSTER3. Чтобы переместить конфигурацию и хранилище виртуальной машины, выполните команду:

```PowerShell
Move-VMStorage -DestinationStoragePath \\SOFS-CLUSTER3\Volume1 -Name MYVM
```

По завершении вы получите предупреждение:

```
WARNING: There were issues updating the virtual machine configuration that may prevent the virtual machine from running. For more information view the report file below.
WARNING: Report file location: C:\Windows\Cluster\Reports\Update-ClusterVirtualMachineConfiguration '' on date at time.htm.
```

Это предупреждение можно проигнорировать, так как предупреждение "не обнаружено изменений в конфигурации хранилища ролей виртуальной машины". Причина предупреждения в том, что фактическое физическое расположение не изменяется; только пути конфигурации.

Дополнительные сведения о Move-Вмстораже см. по этой [ссылке](https://docs.microsoft.com/powershell/module/hyper-v/move-vmstorage?view=win10-ps).

Динамическая миграция виртуальной машины между разными кластерами кластеров отличается от предыдущей. В сценариях, не относящихся к кластеру, эти шаги будут выглядеть следующим образом:

1. Удалите роль виртуальной машины из кластера.
2. Динамическая миграция виртуальной машины в узел-член другого кластера.
3. Добавьте виртуальную машину в кластер в качестве новой роли виртуальной машины.

В кластере эти действия не требуются, и требуется только одна команда. Сначала следует настроить все сети для миграции с помощью команды:

```PowerShell
Set-VMHost -UseAnyNetworkForMigration $true
```

Например, я хочу переместить виртуальную машину с набором кластеров из CLUSTER1 в NODE2-CL3 на CLUSTER3. Единственная команда:

```PowerShell
Move-ClusterSetVM -CimSession CSMASTER -VMName CSVM1 -Node NODE2-CL3
```

Обратите внимание, что это не приводит к перемещению файлов конфигурации и хранилища виртуальных машин. Это не обязательно, так как путь к виртуальной машине остается \\ \\ SOFS-CLUSTER1\VOLUME1. После регистрации виртуальной машины в наборах кластеров путь к общей папке серверного сервера инфраструктуры, диски и виртуальная машина не должны находиться на том же компьютере, что и виртуальная машина.

## <a name="creating-availability-sets-fault-domains"></a>Создание доменов сбоя для групп доступности

Как описано в статье Общие сведения о доменах сбоя и группах доступности Azure можно настроить в наборе кластеров. Это полезно для первоначального размещения виртуальных машин и миграции между кластерами.

В приведенном ниже примере в наборе кластеров участвуют четыре кластера. В наборе логический домен сбоя будет создан с двумя кластерами и доменом сбоя, созданным с двумя другими кластерами. Эти два домена сбоя будут состоять из набора новой.

В приведенном ниже примере CLUSTER1 и CLUSTER2 будут находиться в домене сбоя с именем **дс1 —** , а CLUSTER3 и CLUSTER4 будут находиться в домене сбоя с именем **FD2**. Группа доступности будет называться **ксмастер-AS** и состоять из двух доменов сбоя.

Чтобы создать домены сбоя, выполните следующие команды:

```PowerShell
New-ClusterSetFaultDomain -Name FD1 -FdType Logical -CimSession CSMASTER -MemberCluster CLUSTER1,CLUSTER2 -Description "This is my first fault domain"

New-ClusterSetFaultDomain -Name FD2 -FdType Logical -CimSession CSMASTER -MemberCluster CLUSTER3,CLUSTER4 -Description "This is my second fault domain"
```

Чтобы убедиться, что они были успешно созданы, можно запустить Get-Клустерсетфаултдомаин с отображаемыми выходными данными.

```PowerShell
PS C:\> Get-ClusterSetFaultDomain -CimSession CSMASTER -FdName FD1 | fl *

PSShowComputerName    : True
FaultDomainType       : Logical
ClusterName           : {CLUSTER1, CLUSTER2}
Description           : This is my first fault domain
FDName                : FD1
Id                    : 1
PSComputerName        : CSMASTER
```

Теперь, когда домены сбоя созданы, необходимо создать группу доступности.

```PowerShell
New-ClusterSetAvailabilitySet -Name CSMASTER-AS -FdType Logical -CimSession CSMASTER -ParticipantName FD1,FD2
```

Чтобы проверить, что он создан, используйте:

```PowerShell
Get-ClusterSetAvailabilitySet -AvailabilitySetName CSMASTER-AS -CimSession CSMASTER
```

При создании новых виртуальных машин необходимо использовать параметр-Availability в процессе определения оптимального узла. Поэтому он будет выглядеть примерно так:

```PowerShell
# Identify the optimal node to create a new virtual machine
$memoryinMB=4096
$vpcount = 1
$av = Get-ClusterSetAvailabilitySet -Name CSMASTER-AS -CimSession CSMASTER
$targetnode = Get-ClusterSetOptimalNodeForVM -CimSession CSMASTER -VMMemory $memoryinMB -VMVirtualCoreCount $vpcount -VMCpuReservation 10 -AvailabilitySet $av
$secure_string_pwd = convertto-securestring "<password>" -asplaintext -force
$cred = new-object -typename System.Management.Automation.PSCredential ("<domain\account>",$secure_string_pwd)
```

Удаление кластера из наборов кластеров из-за различных жизненных циклов. Иногда требуется удалить кластер из набора кластеров. Рекомендуется переместить все виртуальные машины из кластера в кластер. Это можно сделать с помощью команд **Move-клустерсетвм** и **Move-вмстораже** .

Однако если виртуальные машины также не будут перемещены, наборы кластеров выполняют ряд действий, чтобы обеспечить интуитивно понятный результат администратору. При удалении кластера из набора все остальные виртуальные машины, размещенные в удаляемом кластере, будут просто становиться высокодоступными виртуальными машинами, привязанными к этому кластеру, предполагая, что у них есть доступ к их хранилищу. Наборы кластеров также будут автоматически обновлять свои инвентаризации:

- Больше не отслеживает работоспособность уже удаленного кластера и работающих на нем виртуальных машин.
- Удаляет из пространства имен набора кластеров и все ссылки на общие ресурсы, размещенные в удаленном кластере

Например, команда для удаления кластера CLUSTER1 из наборов кластеров будет выглядеть так:

```PowerShell
Remove-ClusterSetMember -ClusterName CLUSTER1 -CimSession CSMASTER
```

## <a name="frequently-asked-questions-faq"></a>Вопросы и ответы

**Вопрос:** В наборе кластеров я могу использовать только кластеры с технологией Hyper-in? <br>
**Ответ.** Нет. Вы можете смешивать Локальные дисковые пространства с традиционными кластерами.

**Вопрос:** Можно ли управлять набором кластеров с помощью System Center Virtual Machine Manager? <br>
**Ответ.** В настоящее время System Center Virtual Machine Manager не поддерживает наборы кластеров <br><br> **Вопрос:** Могут ли совместно существовать кластеры Windows Server 2012 R2 или 2016 в одном наборе кластеров? <br>
**Вопрос:** Можно ли перенести рабочие нагрузки из кластеров Windows Server 2012 R2 или 2016, просто присоединить эти кластеры к одному набору кластеров? <br>
**Ответ.** Наборы кластеров — это новая технология, появившаяся в Windows Server 2019, поэтому она не существует в предыдущих выпусках. Кластеры под управлением ОС нижнего уровня не могут присоединиться к набору кластеров. Однако технология чередующегося обновления операционной системы кластера должна предоставить необходимые функции для миграции, обновив эти кластеры до Windows Server 2019.

**Вопрос:** Можно ли использовать наборы кластеров для масштабирования хранилища или вычислений (отдельно)? <br>
**Ответ.** Да, путем простого добавления дискового пространства с прямым или традиционным кластером Hyper-V. С помощью кластерных наборов это очень простое изменение соотношения вычислений и хранилища даже в наборе кластеров с согласованием.

**Вопрос:** Что такое средства управления для наборов кластеров <br>
**Ответ.** PowerShell или WMI в этом выпуске.

**Вопрос:** Как будет работать динамическая миграция между кластерами с процессорами разных поколений?  <br>
**Ответ.** Наборы кластеров не поддерживают различия между процессорами и заменяют возможности Hyper-V, поддерживаемые в настоящее время. Поэтому режим совместимости процессора должен использоваться с быстрыми переносами. Рекомендации для наборов кластеров — использование одного и того же оборудования процессора в каждом отдельном кластере, а также всего набора кластеров для динамической миграции между кластерами.

**Вопрос:** Может ли мой кластер устанавливать виртуальные машины автоматически отработка отказа при сбое кластера?  <br>
**Ответ.** В этом выпуске виртуальные машины с набором кластеров можно только вручную перенести в кластеры. но не может автоматически отработки отказа.

**Вопрос:** Как обеспечить устойчивость хранилища к сбоям кластера? <br>
**Ответ.** Используйте решение реплики хранилища между кластерами (SR) в кластерах участников, чтобы реализовать устойчивость хранилища к сбоям кластера.

**Вопрос:** Я использую реплику хранилища (SR) для репликации между кластерами-членами. Меняются ли пути UNC хранилища пространства имен в хранилище SR для отработки отказа на целевой объект реплики Локальные дисковые пространства кластере? <br>
**Ответ.** В этом выпуске изменение ссылок на пространство имен набора кластеров не происходит при отработке отказа SR. Сообщите корпорации Майкрософт о том, является ли этот сценарий критически важным для вас и как вы планируете его использовать.

**Вопрос:** Возможна ли отработка отказа виртуальных машин между доменами сбоя в ситуации аварийного восстановления (предположим, что весь домен сбоя был остановлен)? <br>
**Ответ.** Нет, обратите внимание, что отработка отказа между кластерами в логическом домене сбоя пока не поддерживается.

**Вопрос:** Может ли мой кластер занимать кластеры на нескольких сайтах (или доменах DNS)? <br>
**Ответ.** Это нетестовый сценарий, который не планируется немедленно для поддержки в рабочей среде. Сообщите корпорации Майкрософт о том, является ли этот сценарий критически важным для вас и как вы планируете его использовать.

**Вопрос:** Работает ли набор кластеров с IPv6? <br>
**Ответ.** Как IPv4, так и IPv6 поддерживаются с наборами кластеров в качестве отказоустойчивых кластеров.

**Вопрос:** Требования к лесу Active Directory для наборов кластеров <br>
**Ответ.** Все кластеры элементов должны находиться в одном лесу AD.

**Вопрос:** Сколько кластеров или узлов может быть частью одного набора кластеров? <br>
**Ответ.** В Windows Server 2019 наборы кластеров были протестированы и поддерживаются до 64 всего узлов кластера. Однако кластер устанавливает масштаб в более крупные ограничения и не является жестко закодированным для ограничения. Сообщите корпорации Майкрософт о том, что для вас важна большая шкала, и как вы планируете его использовать.

**Вопрос:** Будут ли все Локальные дисковые пространства кластеры в наборе кластера образовывать один пул носителей? <br>
**Ответ.** Нет. Локальные дисковые пространства технология по-прежнему работает в одном кластере, а не в кластерах-членах в наборе кластеров.

**Вопрос:** Является ли пространство имен набора кластеров высокодоступным? <br>
**Ответ.** Да, пространство имен кластера предоставляется через постоянно доступный сервер пространства имен SOFS (CA), работающий в кластере управления. Корпорация Майкрософт рекомендует использовать достаточное количество виртуальных машин из кластеров-членов, чтобы сделать их устойчивыми к локализованным сбоям в кластере. Тем не менее, чтобы учитывать непредвиденные разрушительные сбои, например, все виртуальные машины в кластере управления переключаются в одно и то же время — справочные сведения дополнительно кэшируются в каждом узле набора кластеров даже при перезагрузке.

**Вопрос:** Замедлит ли кластер доступ к хранилищу на основе пространства имен в наборе кластеров? <br>
**Ответ.** Нет. Пространство имен набора кластеров предлагает пространство имен ссылки оверлея в наборе кластеров, как концептуально, например распределенная файловая система пространства имен (ДФСН). И, в отличие от ДФСН, все метаданные, заданные в виде ссылок на все кластерные пространства имен, автоматически заполняются и автоматически обновляются на всех узлах без вмешательства администратора, поэтому в пути доступа к хранилищу почти нет никаких издержек на производительность.

**Вопрос:** Как выполнять резервное копирование метаданных набора кластеров? <br>
**Ответ.** Это то же руководство, что и для отказоустойчивого кластера. Резервная копия состояния системы также будет создавать резервную копию состояния кластера. С помощью cистема архивации данных Windows Server можно выполнить восстановление только базы данных кластера узла (которая никогда не нужна из-за имеющейся в ней логики самовосстановления) или выполнить полномочное восстановление для отката всей базы данных кластера на всех узлах. В случае с наборами кластеров Корпорация Майкрософт рекомендует сначала выполнить такое полномочное восстановление в кластере участников, а затем кластер управления, если это необходимо.
