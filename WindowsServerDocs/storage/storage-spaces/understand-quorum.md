---
title: Основные сведения о кворума кластера и пула
description: Основные сведения о кластере и кворума пула с конкретные примеры к превышению тонкости.
keywords: Дисковые пространства, кворума, следящий сервер, S2D, кластера кластере кворума, пул кворум, пул
ms.prod: windows-server-threshold
ms.author: adagashe
ms.manager: eldenc
ms.technology: storage-spaces
ms.topic: article
author: adagashe
ms.date: 01/18/2019
ms.localizationpriority: medium
ms.openlocfilehash: 24890b191db8bc6934132857e830d4f77c394b02
ms.sourcegitcommit: 0d0b32c8986ba7db9536e0b8648d4ddf9b03e452
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/17/2019
ms.locfileid: "59879975"
---
# <a name="understanding-cluster-and-pool-quorum"></a>Основные сведения о кворума кластера и пула

>Относится к: Windows Server 2019, Windows Server 2016

[Отказоустойчивая кластеризация Windows Server](../../failover-clustering/failover-clustering-overview.md) обеспечивает высокий уровень доступности для рабочих нагрузок. Эти ресурсы, считаются высокой доступности в том случае, если узлы, на которых размещаются ресурсы. Тем не менее, для кластера обычно требуется более половины узлов под управлением, известный как имеющий *кворума*.

Кворум предназначен для предотвращения *дроблением* сценариев, в которых может произойти, когда есть секции в сети и подсети узлов не могут взаимодействовать друг с другом. Это может вызвать оба подмножества узлов, чтобы попытаться владельцем рабочей нагрузки и записи на том же диске, что может привести к множество проблем. Тем не менее это запрещено с помощью отказоустойчивой кластеризации концепция кворума, который обеспечивает только один из этих групп узлов, которые следует продолжать работу, чтобы сохранить только один из этих групп.

Кворум определяет количество сбоев, сохраняя при этом по-прежнему online может выдержать кластер. Кворум предназначен для обработки сценария при наличии проблем со связью между подмножества узлов кластера, таким образом, чтобы несколько серверов не следует пытаться одновременно иметь группу ресурсов и записи на том же диске, в то же время. Когда эта концепция кворума, кластер приведет к службе кластеров для остановки в одном из подмножества узлов, чтобы убедиться, что имеется только один истинного владельца определенной группе ресурсов. После узлы, которые были остановлены снова могут взаимодействовать с основной группе узлов, они будут автоматически повторно присоединиться к кластеру и запустите их служба кластеров.

В Windows Server 2016 имеются два компонента системы, которые имеют собственные механизмы кворума:

- <strong>Кворум кластера</strong>: Это работает на уровне кластера (т. е. можно потерять узлов и кластера, в курсе)
- <strong>Пул кворума</strong>: Это происходит на уровне пула при включении дисковых пространств (т. е. можно потерять узлов и дисков, устраняя пула). Пулы носителей были разработаны для использования в сценариях кластеризованный и некластеризованный, поэтому они имеют разные кворума механизм.

## <a name="cluster-quorum-overview"></a>Общие сведения об кворума кластера

В таблице ниже приводятся общие сведения о кворуме кластера результатов каждого сценария:

| Узлы сервера | Сохраняется в случае сбоя узла один сервер | Можно избежать простоев в случае сбоя узла один сервер, а затем создается другой | Может выдержать сбои два одновременных серверных узлов |
|--------------|-------------------------------------|---------------------------------------------------|----------------------------------------------------|
| 2            | 50/50                               | Нет                                                | Нет                                                 |
| 2 + следящего сервера  | Да                                 | Нет                                                | Нет                                                 |
| 3            | Да                                 | 50/50                                             | Нет                                                 |
| 3 + следящего сервера  | Да                                 | Да                                               | Нет                                                 |
| 4            | Да                                 | Да                                               | 50/50                                              |
| 4 + следящего сервера  | Да                                 | Да                                               | Да                                                |
| 5 и более поздних версий  | Да                                 | Да                                               | Да                                                |

### <a name="cluster-quorum-recommendations"></a>Рекомендации кворума кластера

- Если у вас есть два узла, следящий сервер, то <strong>требуется</strong>.
- При наличии трех или четырех узлов, следящий сервер находится <strong>настоятельно рекомендуется</strong>.
- Если у вас есть доступ к Интернету, используйте  <strong>[облако-свидетель](../../failover-clustering/deploy-cloud-witness.md)</strong>
- Если вы в ИТ-среде с другими машинами и общих папок, использование файлового ресурса-свидетеля

## <a name="how-cluster-quorum-works"></a>Как работает кворума кластера

При сбое узлов или некоторое подмножество узлов теряет контакт с другой набор, уцелевшие узлы необходимо подтвердить, что они составляют *большинство* кластера могут оставаться в сети. Если они не может проверить, они будут автономный.

Однако концепция *большинство* работает только аккуратно при нечетное число узлов в кластере (например, три узла в кластере из пяти узлов). Таким образом как насчет кластеры с четным числом узлов (скажем, кластера с четырьмя узлами)?

Кластер можно сделать двумя способами *общее число голосов* странным:

1. Во-первых, он может переходить *вверх* путем добавления *следящий сервер* с дополнительный голос. Это требует настройки пользователя.
2.  Или можно разместить *вниз* один путем обнуления один повезет голос этого узла (происходит автоматически, при необходимости).

Каждый раз, когда успешно сохранивших работоспособность узлах подтвердить он *большинство*, определение *большинство* обновляется, чтобы стать одним из только что оставшихся объектов. Это позволяет кластеру потерять один узел другой, а затем другой и т. д. Эта концепция *общее число голосов* адаптации после последовательных сбоев называется  <strong>*динамический кворум*</strong>.  

### <a name="dynamic-witness"></a>Динамические следящего сервера

Динамические следящий сервер переключает голосов следящего сервера, чтобы убедиться в том, что *общее число голосов* является нечетным. Если нечетное число голосов, следящий сервер не имеет голоса. Если четное число голосов, голос имеет следящего сервера. Динамические следящего сервера значительно снижает риск того, что кластер завершает работу из-за сбоя следящего сервера. Кластера решает, следует ли использовать голоса свидетеля, на основе числа узлов с правом голоса, доступных в кластере.

Динамический кворум работает с динамической следящего сервера, как описано ниже.

### <a name="dynamic-quorum-behavior"></a>Поведение динамический кворум

- Если у вас есть <strong>даже</strong> количество узлов и без свидетеля *один узел получает свой голос за zeroed*. К примеру, только три из четырех узлов получения голосов, поэтому *общее число голосов* равно 3, а два оставшихся объектов с голосами считаются большинства.
- Если у вас есть <strong>нечетное</strong> количество узлов и без свидетеля *всех них голосов*.
- Если у вас есть <strong>даже</strong> число узлов, а также для следящего сервера, *голосов следящий сервер*, поэтому общее число нечетное.
- Если у вас есть <strong>нечетное</strong> число узлов, а также для следящего сервера, *следящий сервер не проголосовать*.

Динамический кворум дает возможность назначить голос узла динамически, чтобы не потерять большинство голосов и разрешить работы кластера с одним узлом (известный как положение последнего man). В качестве примера рассмотрим четырех узлов кластера. Предположим, что кворума требуется 3 голоса. 

В этом случае кластер будет перестал работать при отключении двух узлов.

![Схема, показывающая с четырьмя узлами кластера, каждый из которых получает голос](media/understand-quorum/dynamic-quorum-base.png)

Однако динамический кворум предотвращает указанные последствия. *Общее число голосов* необходимые для кворума теперь определяется на основе количества доступных узлов. Таким образом с помощью динамический кворум кластера будет работать даже в случае утери три узла.

![Схема, показывающая четырех узлов кластера, с узлов, сбой одной за раз и число необходимых голосов, настройка после каждой ошибки.](media/understand-quorum/dynamic-quorum-step-through.png)

Описанный выше сценарий применяется к общие кластера, у которых дисковых пространств включено. Тем не менее при включении Storage Spaces Direct, кластер может поддерживать только двух сбоев узлов. Это объясняется более [пула разделе кворума](#poolQuorum).

### <a name="examples"></a>Примеры

#### <a name="two-nodes-without-a-witness"></a>Два узла без следящего сервера. 
Один узел голосов обнуляется, поэтому *большинство* голоса определяется из общего числа <strong>1 голос</strong>. Если без права голоса узел выйдет из строя неожиданно, «выжившую» имеет 1/1, и выдерживает его кластера. Если голосования узел выйдет из строя неожиданно, «выжившую» имеет 0/1 и кластера, выходит из строя. Если узел голосования корректно выключено, голосов переносится на другой узел, и выдерживает его кластера. *<strong>Именно поэтому крайне важно, чтобы настроить следящий сервер.</strong>*

![Как описано в случае с двумя узлами без следящего сервера кворума](media/understand-quorum/2-node-no-witness.png)

- Сохраняется в случае сбоя одного сервера: <strong>Вероятность 50%</strong>.
- Сохраняется в случае сбоя одного сервера, а затем создается другой: <strong>Нет</strong>.
- За один раз может выдержать два сбоя сервера: <strong>Нет</strong>. 

#### <a name="two-nodes-with-a-witness"></a>Два узла со следящим сервером. 
Проголосовать оба узла, а также голосов следящий сервер, поэтому *большинство* определяется из общего числа <strong>3 голосов</strong>. Если либо узел выйдет из строя, «выжившую» имеет 2/3, и выдерживает его кластера.

![Кворум, описано в случае с двумя узлами со следящим сервером](media/understand-quorum/2-node-witness.png)

- Сохраняется в случае сбоя одного сервера: <strong>Да</strong>.
- Сохраняется в случае сбоя одного сервера, а затем создается другой: <strong>Нет</strong>.
- За один раз может выдержать два сбоя сервера: <strong>Нет</strong>. 

#### <a name="three-nodes-without-a-witness"></a>Три узла без следящего сервера.
Проголосовать все узлы, поэтому *большинство* определяется из общего числа <strong>3 голосов</strong>. Если любой узел выйдет из строя, оставшихся объектов, 2 и 3, и выдерживает его кластера. Кластер становится двух узлов без следящего сервера — на этом этапе вы находитесь в сценарии 1.

![Как описано в случае с тремя узлами без следящего сервера кворума](media/understand-quorum/3-node-no-witness.png)

- Сохраняется в случае сбоя одного сервера: <strong>Да</strong>.
- Сохраняется в случае сбоя одного сервера, а затем создается другой: <strong>Вероятность 50%</strong>.
- За один раз может выдержать два сбоя сервера: <strong>Нет</strong>. 

#### <a name="three-nodes-with-a-witness"></a>Три узла со следящим сервером.
Голосовать все узлы, поэтому изначально не проголосовать следящий сервер. *Большинство* определяется из общего числа <strong>3 голосов</strong>. После обнаружения первой ошибки в кластере есть два узла со следящим сервером — то есть сценарий 2. Итак теперь двумя узлами и следящий сервер проголосовать.

![Кворум, описано в случае с тремя узлами со следящим сервером](media/understand-quorum/3-node-witness.png)

- Сохраняется в случае сбоя одного сервера: <strong>Да</strong>.
- Сохраняется в случае сбоя одного сервера, а затем создается другой: <strong>Да</strong>.
- За один раз может выдержать два сбоя сервера: <strong>Нет</strong>. 

#### <a name="four-nodes-without-a-witness"></a>Четыре узла без следящего сервера
Один узел голосов обнуляется, поэтому *большинство* определяется из общего числа <strong>3 голосов</strong>. После обнаружения первой ошибки кластер становится три узла, и вы находитесь в сценарий 3.

![Как описано в случае с четырьмя узлами без следящего сервера кворума](media/understand-quorum/4-node-no-witness.png)

- Сохраняется в случае сбоя одного сервера: <strong>Да</strong>.
- Сохраняется в случае сбоя одного сервера, а затем создается другой: <strong>Да</strong>.
- За один раз может выдержать два сбоя сервера: <strong>Вероятность 50%</strong>. 

#### <a name="four-nodes-with-a-witness"></a>Четыре узла со следящим сервером.
Все голоса узлов и голоса свидетеля, поэтому *большинство* определяется из общего числа <strong>5 голосов</strong>. После обнаружения первой ошибки вы перейдете на сценарий 4. После двух одновременных отказов Перейдите вниз, чтобы сценарий 2.

![Кворум, описано в случае с четырьмя узлами со следящим сервером](media/understand-quorum/4-node-witness.png)

- Сохраняется в случае сбоя одного сервера: <strong>Да</strong>.
- Сохраняется в случае сбоя одного сервера, а затем создается другой: <strong>Да</strong>.
- За один раз может выдержать два сбоя сервера: <strong>Да</strong>. 

#### <a name="five-nodes-and-beyond"></a>Пять узлов и более поздней.
Вы можете проголосовать все узлы, или только один голос, независимо от приводит к вычислению нечетное. Дисковые пространства не может обрабатывать более двух узлов вниз в любом случае, поэтому в этот момент ни один следящий сервер или по требованию полезные.

![Кворум, как описано в случае с пятью узлами и более поздних версий](media/understand-quorum/5-nodes.png)

- Сохраняется в случае сбоя одного сервера: <strong>Да</strong>.
- Сохраняется в случае сбоя одного сервера, а затем создается другой: <strong>Да</strong>.
- За один раз может выдержать два сбоя сервера: <strong>Да</strong>. 

Теперь, когда мы понимаем, как работает кворума, давайте рассмотрим типы свидетелей кворума.

### <a name="quorum-witness-types"></a>Типов свидетеля кворума

Отказоустойчивая кластеризация поддерживает три типа свидетелей кворума:

- <strong>[Облако-свидетель](../../failover-clustering\deploy-cloud-witness.md)</strong>  -BLOB-объектов хранилища в Azure доступны всем узлам кластера. Он поддерживает кластеризации информацию в файле witness.log, но не хранит копию базы данных кластера.
- <strong>Файл ресурса-свидетеля</strong> — файловые ресурсы SMB, настроенный на файловом сервере под управлением Windows Server. Он поддерживает кластеризации информацию в файле witness.log, но не хранит копию базы данных кластера.
- <strong>Диск-свидетель</strong> -small кластеризованный диск, который входит в группу доступное хранилище кластера. Этот диск высокой доступности и отработки отказа между узлами. Он содержит копию базы данных кластера.  <strong>*Диск-свидетель не поддерживается с дисковыми пространствами*</strong>.

## <a id="poolQuorum"></a>Общие сведения о пуле кворума

Мы только что сказали об кворума кластера, которое работает на уровне кластера. Теперь рассмотрим кворума пула, которое работает на уровне пула (т. е. Вы можете потерять узлов и дисков и пул, в курсе). Пулы носителей были разработаны для использования в сценариях кластеризованный и некластеризованный, поэтому они имеют разные кворума механизм.

В таблице ниже приводятся общие сведения о пуле кворума результатов каждого сценария:

| Узлы сервера | Сохраняется в случае сбоя узла один сервер | Можно избежать простоев в случае сбоя узла один сервер, а затем создается другой | Может выдержать сбои два одновременных серверных узлов |
|--------------|-------------------------------------|---------------------------------------------------|----------------------------------------------------|
| 2            | Нет                                  | Нет                                                | Нет                                                 |
| 2 + следящего сервера  | Да                                 | Нет                                                | Нет                                                 |
| 3            | Да                                 | Нет                                                | Нет                                                 |
| 3 + следящего сервера  | Да                                 | Нет                                                | Нет                                                 |
| 4            | Да                                 | Нет                                                | Нет                                                 |
| 4 + следящего сервера  | Да                                 | Да                                               | Да                                                |
| 5 и более поздних версий  | Да                                 | Да                                               | Да                                                |

## <a name="how-pool-quorum-works"></a>Как работает кворума пула

При сбое дисков или некоторого подмножества дисков теряет контакт с другой набор, оставшихся дисков необходимо подтвердить, что они составляют *большинство* пула могут оставаться в сети. Если они не может проверить, они будут автономный. Пул — это сущность, которая переходит в автономный режим или остается доступна в зависимости от того, имеет ли он достаточное количество дисков для кворума (50% + 1). Владелец ресурса пула (активный узел кластера) может быть + 1.

Но кворума пула по-разному работает от кворума кластера одним из следующих способов:

- пул использует один узел в кластере как следящий сервер как решающего, должен быть устойчив половины дисков прошли (этот узел, который является владельцем ресурса пула)
- пул не имеет динамический кворум
- пул не использует свою собственную версию удаление голос

### <a name="examples"></a>Примеры

#### <a name="four-nodes-with-a-symmetrical-layout"></a>Четыре узла с симметричными макета. 
Каждый из 16 дисков имеет один голос, два также имеет один голос (так как он является владельцем ресурса пула). *Большинство* определяется из общего числа <strong>16 голосов</strong>. Если узлы трех и четырех вышли из строя, уцелевшие подмножество состоит из 8 дисков и владелец ресурса пула, являющийся голосов 9/16. Таким образом пул сохраняется.

![Кворума пула 1](media/understand-quorum/pool-1.png)

- Сохраняется в случае сбоя одного сервера: <strong>Да</strong>.
- Сохраняется в случае сбоя одного сервера, а затем создается другой: <strong>Да</strong>.
- За один раз может выдержать два сбоя сервера: <strong>Да</strong>. 

#### <a name="four-nodes-with-a-symmetrical-layout-and-drive-failure"></a>Четыре узла с симметричными ошибки макет и диска. 
Каждый из 16 дисков имеет один голос и узел 2 также имеет один голос (так как он является владельцем ресурса пула). *Большинство* определяется из общего числа <strong>16 голосов</strong>. Во-первых диск 7 выходит из строя. Если узлы трех и четырех вышли из строя, уцелевшие подмножество состоит из 7 дисков и владелец ресурса пула, который является голосов 8/16. Таким образом пул не имеет большую и выходит из строя.

![Кворума пула 2](media/understand-quorum/pool-2.png)

- Сохраняется в случае сбоя одного сервера: <strong>Да</strong>.
- Сохраняется в случае сбоя одного сервера, а затем создается другой: <strong>Нет</strong>.
- За один раз может выдержать два сбоя сервера: <strong>Нет</strong>. 

#### <a name="four-nodes-with-a-non-symmetrical-layout"></a>Четыре узла с не симметричное макета. 
Каждый из 24 дисков имеет один голос, два также имеет один голос (так как он является владельцем ресурса пула). *Большинство* определяется из общего числа <strong>24 голосов</strong>. Если узлы трех и четырех вышли из строя, уцелевшие подмножество состоит из 8 дисков и владелец ресурса пула, который является голосов 9/24. Таким образом пул не имеет большую и выходит из строя.

![Кворума пула 3](media/understand-quorum/pool-3.png)

- Сохраняется в случае сбоя одного сервера: <strong>Да</strong>.
- Сохраняется в случае сбоя одного сервера, а затем создается другой: <strong>Зависит от</strong> (не удается избежать простоев в случае если оба узла, трех и четырех вышли из строя, но сохраняется в случае других сценариев.
- За один раз может выдержать два сбоя сервера: <strong>Зависит от</strong> (не удается избежать простоев в случае если оба узла, трех и четырех вышли из строя, но сохраняется в случае других сценариев.

### <a name="pool-quorum-recommendations"></a>Рекомендации кворума пула

- Убедитесь, что каждый узел в кластере симметричными (каждый узел имеет одинаковое количество дисков)
- Включите трехстороннее зеркало или двойную четность, так что вы можете допустить сбоев узлов и оставить виртуальные диски в оперативное состояние. См. в разделе наших [страница руководства по процессам тома](plan-volumes.md) для получения дополнительных сведений.
- Если более чем двумя узлами не работают или двух узлов и диска на другом узле будут остановлены, тома может не иметь доступа на все три копии данных и поэтому перевести в автономный режим и недоступна. Мы рекомендуем вернуть серверы или замена дисков быстро для того, чтобы обеспечить большинство устойчивость для всех данных в томе.

## <a name="more-information"></a>Дополнительные сведения

- [Настройка и управление кворумом](../../failover-clustering/manage-cluster-quorum.md)
- [Развертывание облака-свидетеля](../../failover-clustering/deploy-cloud-witness.md)
