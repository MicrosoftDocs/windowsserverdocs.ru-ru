---
title: Планирование инфраструктуры программно-конфигурируемой сети
description: В этом разделе содержатся сведения о планировании развертывания инфраструктуры программно-определяемой сети (SDN).
manager: dougkim
ms.custom: na
ms.prod: windows-server
ms.reviewer: na
ms.service: virtual-network
ms.suite: na
ms.technology: networking-sdn
ms.tgt_pltfrm: na
ms.topic: get-started-article
ms.assetid: ea7e53c8-11ec-410b-b287-897c7aaafb13
ms.author: pashort
author: shortpatti
ms.date: 08/10/2018
ms.openlocfilehash: ed2dc8861366b929de346d5bd5b3d40998cc8dd5
ms.sourcegitcommit: 6aff3d88ff22ea141a6ea6572a5ad8dd6321f199
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/27/2019
ms.locfileid: "71355785"
---
# <a name="plan-a-software-defined-network-infrastructure"></a>Планирование инфраструктуры программно-конфигурируемой сети

>Относится к: Windows Server (Semi-Annual Channel), Windows Server 2016

Узнайте о планировании развертывания для программно-определяемой сетевой инфраструктуры, включая требования к оборудованию и программному обеспечению. 


## <a name="prerequisites"></a>Предварительные требования
В этом разделе описывается ряд предварительных требований к оборудованию и программному обеспечению, включая:

-   **Настроенные группы безопасности, расположения файлов журналов и динамическая регистрация DNS** Необходимо подготовить центр обработки данных для развертывания сетевого контроллера, для чего требуется один или несколько компьютеров или виртуальных машин, а также один компьютер или виртуальную машину. Прежде чем можно будет развернуть сетевой контроллер, необходимо настроить группы безопасности, расположения файлов журнала (при необходимости) и динамическую регистрацию DNS.  Если вы не подготовили центр обработки данных для развертывания сетевого контроллера, см. Дополнительные сведения о [требованиях к установке и подготовке для развертывания сетевого](Installation-and-Preparation-Requirements-for-Deploying-Network-Controller.md) контроллера.

-   **Физическая сеть**  Вам потребуется доступ к физическим сетевым устройствам, чтобы настроить виртуальные ЛС, маршрутизацию, BGP, мосты центров обработки данных (ETS) при использовании технологии RDMA и мостового центра обработки данных (коэффициент мощности) при использовании технологии RDMA на основе Роце. В этом разделе показано, как настроить коммутатор вручную, так и пиринг BGP на коммутаторах и маршрутизаторах уровня 3 или на виртуальной машине сервера маршрутизации и удаленного доступа (RRAS).   

-   **Физические узлы вычислений**  Эти узлы работают под управлением Hyper-V и необходимы для размещения инфраструктуры SDN и виртуальных машин клиента.  Для лучшей производительности на этих узлах требуется определенное сетевое оборудование, которое описано далее в разделе **Сетевое оборудование** .  


## <a name="physical-network-and-compute-host-configuration"></a>Конфигурация физической сети и узла вычислений

Каждому физическому узлу вычислений требуется сетевое подключение через один или несколько сетевых адаптеров, подключенных к портам физического коммутатора.  [Виртуальная ЛС](https://en.wikipedia.org/wiki/Virtual_LAN) уровня 2 поддерживает сети, разделенные на несколько логических сегментов сети. 

>[!TIP]
>Используйте виртуальную ЛС 0 для логических сетей в режиме доступа или без тегов. 

>[!IMPORTANT]
>Программно определяемая сеть Windows Server 2016 поддерживает адресацию IPv4 для ундерлай и оверлея. IP версии 6 не поддерживается.

### <a name="logical-networks"></a>Логические сети

#### <a name="management-and-hnv-provider"></a>Поставщик управления и HNV 

Все физические узлы вычислений должны получить доступ к логической сети управления и логической сетью поставщика HNV.  Для целей планирования IP-адресов каждый физический узел вычислений должен иметь по крайней мере один IP-адрес, назначенный в логической сети управления. Сетевому контроллеру требуется зарезервированный IP-адрес, который будет использоваться в качестве IP-адреса для остальных компонентов. 

DHCP-сервер может автоматически назначать IP-адреса для сети управления. также можно назначить статический IP-адрес вручную. Стек SDN автоматически назначает IP-адреса для логических сетей поставщика HNV для отдельных узлов Hyper-V из пула IP-адресов, указанного через сетевой контроллер и управляет им. 

>[!NOTE]
>Сетевой контроллер назначает IP-адрес поставщика HNV физическому узлу вычислений только после того, как агент узла сетевого контроллера получает политику сети для конкретной виртуальной машины клиента. 


|                                                               Если...                                                               |                                                                                                                                                                          То...                                                                                                                                                                           |
|-----------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|                                                  Логические сети используют виртуальные ЛС,                                                  |                                                                 физический узел вычислений должен подключаться к порту с магистральным коммутатором, у которого есть доступ к этим виртуальным ЛС. Важно отметить, что физические сетевые адаптеры на узле компьютера не должны активировать фильтрацию виртуальных ЛС.                                                                 |
|                Использование коммутации внедренных платформ (SET) и нескольких членов группы сетевой карты, таких как сетевые адаптеры,                |                                                                                                                        необходимо подключить всех членов группы сетевых карт для этого конкретного узла к одному домену широковещательной рассылки уровня 2.                                                                                                                         |
| На физическом узле вычислений выполняются дополнительные виртуальные машины инфраструктуры, такие как сетевой контроллер, SLB, МУЛЬТИПЛЕКСОР или шлюз. | Этот узел должен иметь дополнительный IP-адрес, назначенный из логической сети управления для каждой размещенной виртуальной машины.<p>Кроме того, каждая виртуальная машина инфраструктуры SLB и МУЛЬТИПЛЕКСОРа должна иметь IP-адрес, зарезервированный для логической сети поставщика HNV. Невозможность зарезервированного IP-адреса может привести к дублированию IP-адресов в сети. |

---

Сведения о виртуализации сети Hyper-V (HNV), которую можно использовать для виртуализации сетей в развертывании Microsoft SDN, см. в статье [виртуализация сети Hyper-v](../technologies/hyper-v-network-virtualization/Hyper-V-Network-Virtualization.md).  



#### <a name="gateways-and-the-software-load-balancer"></a>Шлюзы и программное обеспечение Load Balancer

Необходимо создать и подготовить дополнительные логические сети для шлюза и использования SLB. Обязательно получите правильные IP-префиксы, идентификаторы виртуальных ЛС и IP-адреса шлюза для этих сетей.


|                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
|---------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|   **Транзитная логическая сеть**   | Шлюз RAS и SLB/МУЛЬТИПЛЕКСОР используют транзитную логическую сеть для обмена данными пиринга BGP и Север/Южный (внешний внутренний) трафик клиента. Размер этой подсети, как правило, меньше, чем у других. Только физические кластерные узлы, на которых выполняется шлюз RAS или виртуальная машина SLB/МУЛЬТИПЛЕКСОРа, должны иметь подключение к этой подсети с помощью этих виртуальных ЛС, размещенных и доступных на портах коммутатора, к которым подключены сетевые адаптеры для вычислений. Каждой виртуальной машине SLB/МУЛЬТИПЛЕКСОРа или шлюза RAS статически назначается один IP-адрес из транзитной логической сети. |
| **Логическая сеть общедоступных виртуальных IP-адресов**  |                                                                                                                             Логическая сеть общедоступных виртуальных IP-адресов необходима для использования префиксов подсети IP, которые маршрутизируются за пределами облачной среды (обычно с возможностью маршрутизации через Интернет).  Это внешние IP-адреса, используемые внешними клиентами для доступа к ресурсам в виртуальных сетях, включая клиентские виртуальные IP-адреса для шлюза "сеть — сеть".                                                                                                                             |
| **Логическая сеть частных виртуальных IP-адресов** |                                                                                                                                                                                       Логическая сеть частных виртуальных IP-адресов не обязана поддерживать маршрутизацию за пределами облака, так как она используется для виртуальных IP-адресов, доступ к которым осуществляется только из внутренних облачных клиентов, таких как SLB диспетчер или частные службы.                                                                                                                                                                                       |
|   **Логическая сеть виртуального IP-адреса GRE**   |                                                                                                                                           Сеть GRE VIP — это подсеть, которая существует исключительно для определения виртуальных IP-адресов, назначенных виртуальным машинам шлюза, которые выполняются в структуре SDN для типа подключения S2S GRE. Эта сеть не требует предварительной настройки в физических коммутаторах или маршрутизаторе, и ей не требуется назначенная виртуальная ЛС.                                                                                                                                            |

---


#### <a name="sample-network-topology"></a>Пример топологии сети
Измените образцы префиксов IP-подсетей и виртуальных ЛС для своей среды. 


| **Сетевое имя** |  **Сетей**  | **Виде** | **ИД виртуальной ЛС в грузовике** | **Роль**  |                                                           **Резервирования (примеры)**                                                           |
|------------------|--------------|----------|----------------------|--------------|-------------------------------------------------------------------------------------------------------------------------------------------------|
|    Management    | 10.184.108.0 |    24    |          7           | 10.184.108.1 | 10.184.108.1 — маршрутизатор 10.184.108.4 — сетевой контроллер 10.184.108.10 — COMPUTE Host 110.184.108.11 — COMPUTE Host 210.184.108. X — вычисление узла X |
|   Поставщик HNV   |  10.10.56.0  |    23    |          11          |  10.10.56.1  |                                                    10.10.56.1 — маршрутизатор 10.10.56.2-SLB/MUX1                                                     |
|     Общественном      |  10.10.10.0  |    24    |          10          |  10.10.10.1  |                                                               10.10.10.1 — маршрутизатор                                                               |
|    Общедоступный виртуальный IP-адрес    |  41.40.40.0  |    27    |          Н/Д          |  41.40.40.1  |                                    41.40.40.1 — 41.40.40.2 маршрутизатора — виртуальный IP-адрес SLB/МУЛЬТИПЛЕКСОРа 41.40.40.3 — IPSec S2S VPN.                                    |
|   Частный виртуальный IP-адрес    |  20.20.20.0  |    27    |          Н/Д          |  20.20.20.1  |                                                        20.20.20.1-Default GW (маршрутизатор)                                                         |
|     ВИРТУАЛЬНЫЙ IP-АДРЕС GRE      |  31.30.30.0  |    24    |          Н/Д          |  31.30.30.1  |                                                             31.30.30.1-по умолчанию GW                                                             |

---

### <a name="logical-networks-required-for-rdma-based-storage"></a>Логические сети, необходимые для хранилища на основе RDMA  

При использовании хранилища на основе RDMA определите виртуальную ЛС и подсеть для каждого физического адаптера (два адаптера на узел) на узлах вычислений и хранения.  

>[!IMPORTANT]
>Чтобы обеспечить надлежащее применение качества обслуживания (QoS), для физических коммутаторов требуется наличие помеченных VLAN для трафика RDMA.

| **Сетевое имя** |  **Сетей**  | **Виде** | **ИД виртуальной ЛС в грузовике** | **Роль**  |                                                           **Резервирования (примеры)**                                                            |
|------------------|--------------|----------|----------------------|--------------|--------------------------------------------------------------------------------------------------------------------------------------------------|
|     Storage1     |  10.60.36.0  |    25    |          8           |  10.60.36.1  |  10.60.36.1 — маршрутизатор<p>10.60.36. X — узел вычислений X<p>10.60.36. y — вычисление узла Y<p>10.60.36. V — расчетный кластер<p>10.60.36. W — кластер хранилища  |
|     Storage2     | 10.60.36.128 |    25    |          9           | 10.60.36.129 | 10.60.36.129 — маршрутизатор<p>10.60.36. X — узел вычислений X<p>10.60.36. y — вычисление узла Y<p>10.60.36. V — расчетный кластер<p>10.60.36. W — кластер хранилища |

---


## <a name="routing-infrastructure"></a>Инфраструктура маршрутизации  

Если вы развертываете инфраструктуру SDN с помощью сценариев, подсети "Управление", "поставщик HNV", "транзитный" и "виртуальный IP-адрес" должны поддерживать маршрутизацию друг на друга в физической сети.     

Сведения о \(маршрутизации, например "следующий\) прыжок" для подсетей виртуальных IP-адресов, объявляются шлюзами SLB/мультиплексора и RAS в физической сети с помощью внутреннего пиринга BGP. Для логических сетей виртуальных IP-адресов не назначена виртуальная ЛС, и они не были предварительно настроены в коммутаторе уровня 2 (например, в коммутаторе верхнего уровня).  

Необходимо создать узел BGP на маршрутизаторе, который используется в инфраструктуре SDN для получения маршрутов для логических сетей виртуальных IP-адресов, объявленных шлюзами SLB/мультиплексоров и RAS. Пиринг BGP должен выполняться только один путь (от SLB, МУЛЬТИПЛЕКСОРа или шлюза RAS к внешнему узлу BGP).  Выше первого уровня маршрутизации можно использовать статические маршруты или другой протокол динамической маршрутизации, такой как OSPF. Однако, как было сказано выше, префикс подсети IP для логических сетей виртуальных IP-адресов должен быть направляем из физической сети на внешний узел BGP.   

Пиринг BGP обычно настраивается в управляемом коммутаторе или маршрутизаторе в составе сетевой инфраструктуры. Узел BGP также можно настроить на сервере Windows Server с ролью сервера удаленного доступа (RAS), установленной в режиме только маршрутизации. На этом узле маршрутизатора BGP в сетевой инфраструктуре необходимо настроить собственный ASN и разрешить пиринг из ASN, назначенного компонентам \(Sdn/мультиплексора и\)шлюзам RAS. Необходимо получить от физического маршрутизатора следующие сведения или сетевой администратор, управляющий этим маршрутизатором:

- Маршрутизатор ASN  
- IP-адрес маршрутизатора  
- ASN для использования компонентами SDN (может быть любым числом из частного диапазона ASN)

>[!NOTE]
>SLB или МУЛЬТИПЛЕКСОР не поддерживает четыре байта ASN. Необходимо выделить два байта ASN для SLB/МУЛЬТИПЛЕКСОРа и соединения маршрутизатора, к которому он подключается. Вы можете использовать 4-байтовый ASN в любом расположении в вашей среде.  

Вы или администратор сети должны настроить узел маршрутизатора BGP на прием подключений из ASN и IP-адреса или адреса подсети транзитной логической сети, которые используются шлюзом RAS и SLB/мультиплексоров.

Дополнительные сведения см. в разделе [протокол BGP (BGP)](../../../remote/remote-access/bgp/Border-Gateway-Protocol-BGP.md).

## <a name="default-gateways"></a>Шлюзы по умолчанию
Компьютеры, настроенные для подключения к нескольким сетям, например физические узлы и виртуальные машины шлюза, должны иметь только один настроенный шлюз по умолчанию. Настройте шлюз по умолчанию для адаптера, используемого для доступа в Интернет.

Для виртуальных машин используйте следующие правила, чтобы решить, какую сеть использовать в качестве шлюза по умолчанию.

1. Используйте транзитную логическую сеть в качестве шлюза по умолчанию, если виртуальная машина подключается к транзитной сети или если она находится в нескольких сетевых подключениях к транзитной сети или любой другой сети.
2. Используйте сеть управления в качестве шлюза по умолчанию, если виртуальная машина подключается только к сети управления. 
3. Используйте сеть поставщика HNV для шлюзов SLB/мультиплексоров и RAS. Не используйте сеть поставщика HNV в качестве шлюза по умолчанию. 
4. Не подключайте виртуальные машины непосредственно к сетям Storage1, Storage2, общедоступного или частного виртуального IP-адреса.

Для узлов и узлов хранилища Hyper-V используйте сеть управления в качестве шлюза по умолчанию.  В сетях хранилища никогда не должно быть назначен шлюз по умолчанию.


## <a name="network-hardware"></a>Сетевое оборудование

Для планирования развертывания сетевого оборудования можно использовать следующие разделы.

### <a name="network-interface-cards-nics"></a>Сетевые платы

Сетевые карты, используемые на узлах Hyper-V и узлах хранения, нуждаются в конкретных возможностях для достижения наилучшей производительности. 

Удаленный доступ к памяти (RDMA) — это методика обхода ядра, которая позволяет передавать большие объемы данных без использования центрального процессора узла, освобождая ЦП для выполнения других задач. 

Включение объединения внедренных компонентов (SET) — это альтернативное решение для объединения сетевых карт, которое можно использовать в средах, включающих Hyper-V и стек программно-определяемых сетей (SDN) в Windows Server 2016. Установите некоторые функции объединения сетевых карт в виртуальный коммутатор Hyper-V. 

Дополнительные сведения см. в разделе [Удаленный доступ к памяти (RDMA) и объединение коммутаторов (Set) Embedded](../../../virtualization//hyper-v-virtual-switch/RDMA-and-Switch-Embedded-Teaming.md).   

Чтобы учитывать расходы на трафик виртуальной сети клиента, вызванные заголовком инкапсуляции вкслан или NVGRE, значение MTU сети уровня 2 (коммутаторы и узлы) должно быть больше или равно 1674 байт \(, включая Ethernet уровня 2. заголовки\). 

Сетевые карты, поддерживающие новое ключевое слово New *енкаповерхеад* Adapter, устанавливают значение MTU автоматически через агент узла сетевого контроллера. Сетевые карты, не поддерживающие новое ключевое слово енкаповерхеад, должны вручную задавать размер MTU на каждом физическом узле с помощью ключевого слова *жумбопаккет* \(или эквивалентного. \) 


### <a name="switches"></a>Аргументы

При выборе физического коммутатора и маршрутизатора для своей среды Убедитесь, что он поддерживает следующий набор возможностей:  

- Требуются параметры \(MTU свитчпорт\)  
- MTU имеет значение > = 1674 байт \(, включая заголовок L2-Ethernet.\)  
- Требуются протоколы \(L3\)  
- ECMP  
- BGP \(IETF RFC 4271\)\-на основе ECMP

Реализации должны поддерживать операторы for в следующих стандартах IETF.

- RFC 2545: "Расширения протокола BGP 4 для маршрутизации между доменами IPv6"  
- RFC 4760: "Многопротокольные расширения для BGP-4"  
- RFC 4893: "Поддержка BGP для четырех октетов в качестве пространства номеров"  
- RFC 4456: "Отражение маршрута BGP: Альтернатива полной внутренней сети BGP (ИБГП)  
- RFC 4724: "Механизм корректного перезапуска BGP"  

Требуются следующие протоколы разметки.

- Виртуальная ЛС — изоляция различных типов трафика
- 802.1 q

Следующие элементы обеспечивают управление ссылками.

- Коэффициент компенсаций \(качества обслуживания требуется только при использовании роце\)
- Расширенный выбор \(трафика 802.1 Каз\)
- Управление \(потоком на основе приоритетов 802.1 p/Q и 802.1 КББ\)

Следующие элементы обеспечивают доступность и избыточность.

- Переключение доступности (обязательно)
- Для выполнения функций шлюза требуется маршрутизатор высокой доступности. Это можно сделать с помощью коммутатора в нескольких корпусах, маршрутизатора или технологий, таких как VRRP.

Следующие элементы предоставляют возможности управления.

**Производительность**

- Протокол SNMP v1 или SNMP v2 (требуется при использовании сетевого контроллера для мониторинга физического коммутатора)  
- При использовании \(сетевого контроллера для мониторинга физического коммутатора требуются MIB SNMP.\)  
- MIB-II (RFC 1213), LLDP, интерфейс MIB \(RFC 2863\), IF-MIB, IP-MIB, IP-Forward-MIB, Q-Bridge-MIB, мост-MIB, LLDB-MIB, Entity-MIB, IEEE8023-Lag-MIB  

На следующих диаграммах показан пример установки с четырьмя узлами. В целях ясности на первой схеме показан только сетевой контроллер, второй показывает сетевой контроллер и программную подсистему балансировки нагрузки, а третья диаграмма показывает сетевой контроллер, программную подсистему балансировки нагрузки и шлюз.  

В этих диаграммах не отображаются сети хранения данных и vNIC. Если вы планируете использовать хранилище на основе SMB, это необходимо.

Виртуальные машины инфраструктуры и клиента можно распространять на любом физическом узле вычислений (при условии, что для правильных логических сетей существует правильное сетевое подключение).  



## <a name="switch-configuration-examples"></a>Примеры конфигурации коммутатора  

Чтобы настроить физический коммутатор или маршрутизатор, можно использовать набор примеров файлов конфигурации для различных моделей коммутаторов и поставщиков, доступных в [репозитории GitHub Microsoft Sdn](https://github.com/microsoft/SDN/tree/master/SwitchConfigExamples). Предоставляется подробный файл сведений и проверены команды интерфейса командной строки для конкретных параметров.         


## <a name="compute"></a>Вычисления  
На всех узлах Hyper-V должен быть установлен Windows Server 2016, Hyper-V, а также внешний виртуальный коммутатор Hyper-V, созданный по крайней мере с одним физическим адаптером, подключенным к логической сети управления. Узел должен быть доступен через IP-адрес управления, назначенный узлу управления vNIC.  

Можно использовать любой тип хранилища, совместимый с Hyper-V, Shared или local.   

> [!TIP]  
> Это удобно, если вы используете одно и то же имя для всех виртуальных коммутаторов, но оно не является обязательным. Если планируется развертывание с помощью скриптов, см. комментарий, связанный с `vSwitchName` переменной в файле config. PSD1.  

**Требования к вычислению узла**  
В следующей таблице приведены минимальные требования к оборудованию и программному обеспечению для четырех физических узлов, используемых в примере развертывания.  

Hyper-V|Требования к оборудованию|Требования к программному обеспечению|  
--------|-------------------------|-------------------------  
|Физический узел Hyper-v|4-ядерный ЦП с частотой 2,66 ГГц<br /><br />32 ГБ ОЗУ<br /><br />300 ГБ дискового пространства<br /><br />физический сетевой адаптер объемом 1 ГБ/с (или более мощный)|ЭКВИВАЛЕНТ Windows Server 2016<br /><br />Роль Hyper-V установлена|  


**Требования к роли виртуальной машины для инфраструктуры SDN**  

Role|требования к виртуальных ЦП|Требования к памяти|Требования к диску|  
--------|---------------------|-----------------------|---------------------  
|Сетевой контроллер (три узла)|4 виртуальных ЦП|минимум 4 ГБ (рекомендуется 8 ГБ)|75 ГБ для диска ОС  
|SLB/МУЛЬТИПЛЕКСОР (три узла)|8 виртуальных ЦП|рекомендуется 8 ГБ|75 ГБ для диска ОС  
|Шлюз RAS-сервера<br /><br />(один пул шлюзов из трех узлов, два активных, один пассивный)|8 виртуальных ЦП|рекомендуется 8 ГБ|75 ГБ для диска ОС  
|Маршрутизатор BGP шлюза RAS для пиринга SLB/МУЛЬТИПЛЕКСОРа<br /><br />(в качестве альтернативы используйте коммутатор ToR в качестве маршрутизатора BGP)|2 виртуальных ЦП|2 ГБ|75 ГБ для диска ОС|  


При использовании VMM для развертывания требуются дополнительные ресурсы виртуальной машины инфраструктуры для VMM и другой инфраструктуры, отличной от SDN. Дополнительные сведения см. в разделе [минимальные рекомендации по оборудованию для System Center Technical Preview.](https://technet.microsoft.com/library/dn997303.aspx)  

## <a name="extending-your-infrastructure"></a>Расширение инфраструктуры  
Требования к размерам и ресурсам для вашей инфраструктуры зависят от виртуальных машин рабочей нагрузки клиента, которые планируется разместить. Требования к ЦП, памяти и диску для виртуальных машин инфраструктуры (например, сетевой контроллер, SLB, шлюз и т. д.) перечислены в предыдущей таблице. Вы можете добавить дополнительные виртуальные машины инфраструктуры, чтобы масштабировать их по мере необходимости. Однако все виртуальные машины клиента, работающие на узлах Hyper-V, имеют собственные требования к ЦП, памяти и диску, которые необходимо учитывать.   

Когда Рабочая нагрузка клиента начинает потреблять слишком много ресурсов на физических узлах Hyper-V, вы можете расширить инфраструктуру, добавив дополнительные физические узлы. Это можно сделать с Virtual Machine Manager или с помощью сценариев PowerShell (в зависимости от того, как изначально развернута инфраструктура) для создания новых ресурсов сервера через сетевой контроллер. Если необходимо добавить дополнительные IP-адреса для сети поставщика HNV, можно создать новые логические подсети (с соответствующими пулами IP-адресов), которые могут использоваться узлами.  


## <a name="see-also"></a>См. также  
[Требования для установки и подготовки к развертыванию сетевого контроллера](Installation-and-Preparation-Requirements-for-Deploying-Network-Controller.md)  
[Программно определяемая сетевая &#40;Sdn&#41;](../Software-Defined-Networking--SDN-.md)  



